apiVersion: workloads.x-k8s.io/v1alpha1
kind: RoleBasedGroup
metadata:
  name: vllm-mooncake-pd
spec:
  roles:
    - name: scheduler
      replicas: 1
      template:
        spec:
          volumes:
            - name: model
              persistentVolumeClaim:
                claimName: llm-model
          containers:
            - name: scheduler
              image: <your-vllm-mooncake-image>
              command:
                - sh
                - -c
                - mooncake_master --port 50001 > mooncake_master.log 2>&1 & ; python3 disagg_proxy_demo.py --port 8000 --model /models/Qwen2.5-7B-Instruct/ --prefill http://$(GROUP_NAME)-prefill-0:8000 http://$(GROUP_NAME)-prefill-1:8000 --decode http://$(GROUP_NAME)-decode-0:8000
              volumeMounts:
                - mountPath: /models/Qwen2.5-7B-Instruct/
                  name: model

    - name: prefill
      replicas: 1
      template:
        spec:
          volumes:
            - name: model
              persistentVolumeClaim:
                claimName: llm-model
          containers:
            - name: vllm-prefill
              image: <your-vllm-mooncake-image>
              command:
                - sh
                - -c
                - >-
                  VLLM_LOGGING_LEVEL=debug MOONCAKE_CONFIG_PATH=/etc/patio/mooncake.json VLLM_USE_V1=0 python3 -m vllm.entrypoints.openai.api_server
                  --model /models/Qwen2.5-7B-Instruct/
                  --port 8000
                  --max-model-len 2048
                  --gpu-memory-utilization 0.95
                  --kv-transfer-config '{"kv_connector":"MooncakeStoreConnector","kv_role":"kv_producer"}'
              ports:
                - containerPort: 8000
              resources:
                limits:
                  nvidia.com/gpu: "1"
              volumeMounts:
                - mountPath: /models/Qwen2.5-7B-Instruct/
                  name: model
                - mountPath: /etc/patio
                  name: patio-group-config
      engineRuntimes:
        - profileName: patio-runtime
          containers:
            - name: patio-runtime
              args:
                - >-
                  --instance-info={
                    "topo_type": "Mooncake",
                    "data": {
                      "metadata_server": "etcd://etcd:2379",
                      "protocol": "tcp",
                      "device_name": "",
                      "master_server_address": "$(GROUP_NAME)-scheduler-0.$(GROUP_NAME)-scheduler:50001"
                    }
                  }
              env:
                - name: TOPO_CONFIG_FILE
                  value: /etc/patio/mooncake.json

    - name: decode
      replicas: 1
      template:
        spec:
          volumes:
            - name: model
              persistentVolumeClaim:
                claimName: llm-model
          containers:
            - name: vllm-decode
              image: <your-vllm-mooncake-image>
              command:
                - sh
                - -c
                - >-
                  VLLM_LOGGING_LEVEL=debug MOONCAKE_CONFIG_PATH=/etc/patio/mooncake.json VLLM_USE_V1=0 python3 -m vllm.entrypoints.openai.api_server
                  --model /models/Qwen2.5-7B-Instruct/
                  --port 8000
                  --max-model-len 2048
                  --gpu-memory-utilization 0.95
                  --kv-transfer-config '{"kv_connector":"MooncakeStoreConnector","kv_role":"kv_consumer"}'
              ports:
                - containerPort: 8000
              resources:
                limits:
                  nvidia.com/gpu: "1"
              volumeMounts:
                - mountPath: /models/Qwen2.5-7B-Instruct/
                  name: model
                - mountPath: /etc/patio
                  name: patio-group-config
      engineRuntimes:
        - profileName: patio-runtime
          containers:
            - name: patio-runtime
              args:
                - >-
                  --instance-info={
                    "topo_type": "Mooncake",
                    "data": {
                      "metadata_server": "etcd://etcd:2379",
                      "protocol": "tcp",
                      "device_name": "",
                      "master_server_address": "$(GROUP_NAME)-scheduler-0.$(GROUP_NAME)-scheduler:50001"
                    }
                  }
              env:
                - name: TOPO_CONFIG_FILE
                  value: /etc/patio/mooncake.json
---
apiVersion: v1
kind: Service
metadata:
  name: mooncake-service
spec:
  type: ClusterIP
  ports:
    - port: 8000
      protocol: TCP
      targetPort: 8000
  selector:
    rolebasedgroup.workloads.x-k8s.io/name: vllm-mooncake-pd
    rolebasedgroup.workloads.x-k8s.io/role: scheduler