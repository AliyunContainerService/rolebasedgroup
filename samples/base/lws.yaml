apiVersion: workloads.x-k8s.io/v1alpha1
kind: RoleBasedGroup
metadata:
  name: vllm-lws
spec:
  roles:
    - name: lws
      workload:
        apiVersion: leaderworkerset.x-k8s.io/v1
        kind: LeaderWorkerSet
      replicas: 1
      leaderWorkerTemplate:
        size: 2
        leaderTemplate:
          metadata:
            labels:
              role: leader
          spec:
            containers:
              - name: vllm-leader
                image: kube-ai-registry.cn-shanghai.cr.aliyuncs.com/kube-ai/vllm:v0.8.4
                command:
                  - sh
                  - -c
                  - "bash /vllm-workspace/examples/online_serving/multi-node-serving.sh leader --ray_cluster_size=$(LWS_GROUP_SIZE); 
                         python3 -m vllm.entrypoints.openai.api_server --port 8000 --model /models/Qwen2.5-7B-Instruct/ "
                resources:
                  limits:
                    nvidia.com/gpu: "1"
                ports:
                  - containerPort: 8000
                readinessProbe:
                  tcpSocket:
                    port: 8000
                  initialDelaySeconds: 15
                  periodSeconds: 10
                volumeMounts:
                  - mountPath: /models/Qwen2.5-7B-Instruct/
                    name: model
            volumes:
              - name: model
                persistentVolumeClaim:
                  claimName: llm-model
        workerTemplate:
          spec:
            containers:
              - name: vllm-worker
                image: kube-ai-registry.cn-shanghai.cr.aliyuncs.com/kube-ai/vllm:v0.8.4
                command:
                  - sh
                  - -c
                  - "bash /vllm-workspace/examples/online_serving/multi-node-serving.sh worker --ray_address=$(LWS_LEADER_ADDRESS)"
                resources:
                  limits:
                    nvidia.com/gpu: "1"
                volumeMounts:
                  - mountPath: /models/Qwen2.5-7B-Instruct/
                    name: model
            volumes:
              - name: model
                persistentVolumeClaim:
                  claimName: llm-model
