apiVersion: workloads.x-k8s.io/v1alpha1
kind: RoleBasedGroup
metadata:
  name: dynamo-pd
spec:
  roles:
    - name: processor
      replicas: 1
      #      workload:
      #        apiVersion: apps/v1
      #        kind: Deployment
      template:
        spec:
          volumes:
            - name: model
              persistentVolumeClaim:
                claimName: llm-model
          containers:
            - name: processor
              command:
                - sh
                - -c
                - "cd /workspace/examples/llm; dynamo serve graphs.disagg-sche-route:Frontend -f configs/disagg-sche-route.yaml"
              env:
                - name: DYNAMO_NAME
                  value: dynamo
                - name: DYNAMO_NAMESPACE
                  value: default
                - name: ETCD_ENDPOINTS
                  value: http://etcd:2379
                - name: NATS_SERVER
                  value: nats://nats:4222
                - name: DYNAMO_RP_TIMEOUT
                  value: "60"
              image: registry-vpc.ap-southeast-1.aliyuncs.com/zibai-test/dynamo:v0.2.0
              ports:
                - containerPort: 8000
                  name: health
                  protocol: TCP
                - containerPort: 9345
                  name: request
                  protocol: TCP
                - containerPort: 443
                  name: api
                  protocol: TCP
                - containerPort: 9347
                  name: metrics
                  protocol: TCP
              readinessProbe:
                initialDelaySeconds: 30
                periodSeconds: 30
                tcpSocket:
                  port: 8000
              resources:
                limits:
                  cpu: "4"
                  memory: 8Gi
                requests:
                  cpu: "4"
                  memory: 8Gi
              volumeMounts:
                - mountPath: /models/Qwen2.5-7B-Instruct/
                  name: model

    - name: prefill
      replicas: 2
      #      workload:
      #        apiVersion: apps/v1
      #        kind: Deployment
      template:
        spec:
          volumes:
            - name: model
              persistentVolumeClaim:
                claimName: llm-model
            - emptyDir:
                medium: Memory
                sizeLimit: 512Mi
              name: shared-memory
          containers:
            - command:
                - sh
                - -c
                - "cd /workspace/examples/llm; dynamo serve graphs.disagg-prefill:PrefillWorker -f configs/disagg-prefill.yaml"
              env:
                - name: DYNAMO_NAME
                  value: dynamo
                - name: DYNAMO_NAMESPACE
                  value: default
                - name: ETCD_ENDPOINTS
                  value: http://etcd:2379
                - name: NATS_SERVER
                  value: nats://nats:4222
                - name: DYNAMO_RP_TIMEOUT
                  value: "60"
              image: registry-vpc.ap-southeast-1.aliyuncs.com/zibai-test/dynamo:v0.2.0
              imagePullPolicy: Always
              name: server
              ports:
                - containerPort: 8000
                  name: health
                  protocol: TCP
                - containerPort: 9345
                  name: request
                  protocol: TCP
                - containerPort: 443
                  name: api
                  protocol: TCP
                - containerPort: 9347
                  name: metrics
                  protocol: TCP
              resources:
                limits:
                  cpu: "4"
                  memory: 16Gi
                  nvidia.com/gpu: "1"
                requests:
                  cpu: "4"
                  memory: 16Gi
                  nvidia.com/gpu: "1"
              volumeMounts:
                - mountPath: /models/Qwen2.5-7B-Instruct/
                  name: model
                - mountPath: /dev/shm
                  name: shared-memory

    - name: decoder
      replicas: 1
#      workload:
#        apiVersion: apps/v1
#        kind: Deployment
      template:
        spec:
          volumes:
            - name: model
              persistentVolumeClaim:
                claimName: llm-model
            - emptyDir:
                medium: Memory
                sizeLimit: 512Mi
              name: shared-memory
          containers:
            - command:
                - sh
                - -c
                - "cd /workspace/examples/llm; dynamo serve graphs.disagg-decode:VllmWorker -f configs/disagg-decode.yaml"
              env:
                - name: DYNAMO_NAME
                  value: dynamo
                - name: DYNAMO_NAMESPACE
                  value: default
                - name: ETCD_ENDPOINTS
                  value: http://etcd:2379
                - name: NATS_SERVER
                  value: nats://nats:4222
                - name: DYNAMO_RP_TIMEOUT
                  value: "60"
              image: registry-vpc.ap-southeast-1.aliyuncs.com/zibai-test/dynamo:v0.2.0
              imagePullPolicy: Always
              name: server
              ports:
                - containerPort: 8000
                  name: health
                  protocol: TCP
                - containerPort: 9345
                  name: request
                  protocol: TCP
                - containerPort: 443
                  name: api
                  protocol: TCP
                - containerPort: 9347
                  name: metrics
                  protocol: TCP
              resources:
                limits:
                  cpu: "4"
                  memory: 16Gi
                  nvidia.com/gpu: "1"
                requests:
                  cpu: "4"
                  memory: 16Gi
                  nvidia.com/gpu: "1"
              volumeMounts:
                - mountPath: /models/Qwen2.5-7B-Instruct/
                  name: model
                - mountPath: /dev/shm
                  name: shared-memory


